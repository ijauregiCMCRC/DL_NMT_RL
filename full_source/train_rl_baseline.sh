python train.py -data ../TRY -save_model ../zh-en/model/BASELINE_RISK_0.2lr/seed_1/EPOCH -encoder_type transformer -decoder_type transformer -enc_layers 6 -dec_layers 6 -label_smoothing 0.1 -src_word_vec_size 512 -tgt_word_vec_size 512 -rnn_size 512 -position_encoding -dropout 0.1 -batch_size 4096 -start_decay_at 20 -report_every 500 -epochs 1 -gpuid 0 -max_generator_batches 16 -batch_type tokens -normalization tokens -accum_count 4 -optim adam -adam_beta2 0.998 -decay_method noam -warmup_steps 8000 -learning_rate 0.2 -max_grad_norm 0 -param_init 0 -param_init_glorot -train_part sentences -train_from ../zh-en/model/BASELINE_AGAIN/seed_1/EPOCH_acc_41.13_ppl_27.11_e16.pt -train_type REINFORCE -beam_size 2 -n_best 2 -seed 1

#python train.py -data ../TRY -save_model ../zh-en/model/BASELINE_AGAIN/seed_1/EPOCH -encoder_type transformer -decoder_type transformer -enc_layers 6 -dec_layers 6 -label_smoothing 0.1 -src_word_vec_size 512 -tgt_word_vec_size 512 -rnn_size 512 -position_encoding -dropout 0.1 -batch_size 4096 -start_decay_at 20 -report_every 500 -epochs 20 -gpuid 0 -max_generator_batches 16 -batch_type tokens -normalization tokens -accum_count 4 -optim adam -adam_beta2 0.998 -decay_method noam -warmup_steps 8000 -learning_rate 2 -max_grad_norm 0 -param_init 0 -param_init_glorot -train_part sentences 

